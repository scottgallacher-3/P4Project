{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a09dbda",
   "metadata": {},
   "source": [
    "## Jupyter Notebook: Code for extracting and processing Zygo/MetroPro data files\n",
    "### Simulating bonds between surface maps, auto-comparison of possible bonded pairs\n",
    "##### Scott Gallacher (2315629), 2020/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6745f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as Rot  # - performing rotations of vectors\n",
    "import scipy.optimize\n",
    "import scipy.ndimage  # - performing rotation of array as image - i.e. around z-axis\n",
    "import copy  # - copy a python object\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm  # - get unique colour maps\n",
    "from itertools import combinations  # - get all N-length combinations from a list\n",
    "from scipy.interpolate import griddata  # - possible interpolation function to fit new x,y positions to original x,y of grid\n",
    "# %matplotlib notebook  # - to make plots interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23f2f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 1x class: \"ZygoMap(filename=None, array=None, map1=None, map2=None, angle=None)\"\n",
    "# - 2(+)x functions to work with pairs of maps:\n",
    "# - - - \"combinemaps(lowermap,uppermap,optimised=True,output=True)\" - lowermap,uppermap are ZygoMap objects\n",
    "# --------- combinemaps uses ztestf() so this is also a distinct function, while testf() (for flattening) can be a class method\n",
    "# --------- could be defined within combinemaps (?) as it's only used there\n",
    "# - - - \"matchdims(map1,map2)\" - map1,map2 are MxN arrays (used from within combinemaps(), using map.heights array)\n",
    "# - - - (possible addition) - to simulate realistic contacts of surfaces when combined (e.g. find 3 points) (would be used by combinemaps())\n",
    "# - - - \"comparebonds\" - to simulate interface (bond) of each combination of available maps, display lowest PV & RMS heights\n",
    "# - - - \"rotatepoints\" - general rotation function made, but has no real use for ZygoMaps as each rotation method has unique needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f26781",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZygoMap:\n",
    "    #structure: definition of methods for the class (to perform operations on the ZygoMap object - referred to as \"self\"):\n",
    "    # - \"zygoread(self, filename)\" - extracting header fields and measurement data from MetroPro .txt files\n",
    "    # ------------------------------ note that the data is not parsed into variables yet, just returned in more useful format\n",
    "    # - \"crop(self, radius=0)\" - (for \"heights\" array) remove data outwith the radius (no crop by default) and centre on the valid data\n",
    "    # - \"testf(self, *args)\" - test/loss function, passed to optimisation algorithm within rotateflat()\n",
    "    # - \"rotateflat(self, array=None)\" - tilt removal by rotating until \"flat\" (minimising peak-to-valley height)\n",
    "    #########\n",
    "    # - \"__str__(self)\" - special method which tells Python how to display the object e.g. when calling print(ZygoMap)\n",
    "    # ------------------- will print out a brief summary of the current object, depending on how it was created\n",
    "    #########\n",
    "    # - \"__init__(self, filename=None, array=None, map1=None, map2=None, angle=None, flatten=True)\"\n",
    "    # -- special method which is always run first by Python when creating object\n",
    "    # -- the main function of the class, initialises the object and performs the pre-processing steps using the methods listed above\n",
    "    # -- any options given during e.g. \"ZygoMap(option1=..., option2=...,)\" get passed straight to __init__()\n",
    "    \n",
    "    def __init__(self, filename=None, array=None, map1=None, map2=None, angle=None, flatten=True):\n",
    "        #initialise ZygoMap object, process to remove tilts and store information about surface and/or from file header\n",
    "        #2 ways to make ZygoMap object:\n",
    "        # - 1) reading in header and data arrays from ASCII .txt file (MetroPro formatting - see reference guide)\n",
    "        # - -  defines a map for a single component, as specified by file (use \"filename\" keyword)\n",
    "        # - 2) supplying an array directly to be processed (using \"array\" keyword)\n",
    "        # - -  particularly needed to store the interface map for combinations of other maps and their optimal angle\n",
    "        # - -  also allows simple user-defined MxN arrays to be provided\n",
    "        \n",
    "        #initialise all variables, whether None or otherwise\n",
    "        #they can all be checked for None elsewhere, but it's best to make sure they exist\n",
    "        self.filename = filename\n",
    "        self.array = array\n",
    "        self.map1 = map1\n",
    "        self.map2 = map2\n",
    "        self.angle = angle\n",
    "        self.flatten = flatten\n",
    "        \n",
    "        if (filename is None) & (array is None):\n",
    "            raise AttributeError(\"\"\"Cannot construct map object - please explicitly supply either\n",
    "                                 \\\"filename\\\" as a local file location or\n",
    "                                 \\\"array\\\" as a 2D numpy array\n",
    "                                 as arguments to begin processing.\"\"\")\n",
    "            \n",
    "        elif (filename is not None) & (array is not None):\n",
    "            filename = None\n",
    "            self.filename = None  # - possibly unnecessary - could change all checks after initial setting to self.[argument] instead of [argument]\n",
    "            print(\"\"\"Warning: Both \\\"filename\\\" and \\\"array\\\" arguments were provided. The initialisation will proceed using \\\"array\\\" argument.\"\"\")\n",
    "        \n",
    "        if array is not None:\n",
    "            if isinstance(array, np.ndarray):\n",
    "                if (len(array.shape) == 2) & (0 not in array.shape):\n",
    "                    self.heights = array.copy()\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid array dimensions - NxM 2D array shape required.\")\n",
    "            else:\n",
    "                raise AttributeError(\"\"\"Could not process given argument. \\\"array\\\" argument requires an NxM 2D numpy array.\"\"\")\n",
    "                \n",
    "            #allow map object to be created from scratch (i.e. make interface as a map object directly)\n",
    "            #set info about interface's source maps and their combination\n",
    "            #leave default as None, this is only applicable to interfaces created out of combinemaps\n",
    "            #which provides the 2 filenames and optimised angle\n",
    "            #test if this is a combination of maps (interface) or user-defined single map (\"map1\",\"map2\",\"angle\" do not apply)\n",
    "            self.heights = array.copy()\n",
    "        \n",
    "        elif filename is not None:\n",
    "            self.filename = filename\n",
    "            #get header and data from file by user-defined function \"zygoread\" (change to class method ?)\n",
    "            fields, data = self.zygoread(filename)\n",
    "\n",
    "            #header extraction\n",
    "            self.stringConstant = fields[0][0]\n",
    "            chunk = fields[0][1].split()\n",
    "            self.softwareType, self.majorVersion, self.minorVersion, self.bugVers = [int(n) for n in chunk]\n",
    "\n",
    "            self.softwareDate = fields[1][0]\n",
    "\n",
    "            chunk = fields[2][0].split()\n",
    "            self.intensOriginX, self.intensOriginY, self.intensWidth, self.intensHeight, self.Nbuckets, self.intensRange = [int(n) for n in chunk]\n",
    "\n",
    "            chunk = fields[2][1].split()\n",
    "            self.phaseOriginX, self.phaseOriginY, self.phaseWidth, self.phaseHeight = [int(n) for n in chunk]\n",
    "\n",
    "            self.comment = fields[3][0]\n",
    "\n",
    "            self.partSerNum = fields[4][0]\n",
    "            self.partNum = fields[5][0]\n",
    "\n",
    "            chunk = fields[6][0].split()\n",
    "            self.source = int(chunk.pop(0))  # - want 1st and last separately (they are int, rest are float)\n",
    "            self.timeStamp = int(chunk.pop(-1))  # - use .pop(index) to separate the item from the list\n",
    "            self.intfScaleFactor, self.wavelengthIn, self.numericAperture, self.obliquityFactor, self.magnification, self.cameraRes = [float(n) for n in chunk]\n",
    "\n",
    "            chunk = fields[6][1].split()\n",
    "            self.cameraWidth, self.cameraHeight, self.systemType, self.systemBoard, self.systemSerial, self.instrumentId = [int(n) for n in chunk]\n",
    "\n",
    "            self.objectiveName = fields[7][0]\n",
    "\n",
    "            #want both index 6 & 7 seperately, as they need to be floats\n",
    "            #convert the rest to int as before\n",
    "            chunk = fields[8][0].split()  # - looks messier but should use this throughout to reduce repeated splitting\n",
    "            self.targetRange = float(chunk.pop(6))  # - remove item at index 6 and returns it (and modifies original list)\n",
    "            self.lightLevel = float(chunk.pop(6))  # - do it again as the index 7 is now at index 6 in the modified list\n",
    "            self.acquireMode, self.intensAvgs, self.PZTCal, self.PZTGain, self.PZTGainTolerance, self.AGC, self.minMod, self.minModPts = [int(n) for n in chunk]\n",
    "\n",
    "            chunk = fields[8][1].split()\n",
    "            self.disconFilter = float(chunk.pop(4))\n",
    "            self.phaseRes, self.phaseAvgs, self.minimumAreaSize, self.disconAction, self.connectionOrder, self.removeTiltBias, self.dataSign, self.codeVType = [int(n) for n in chunk]\n",
    "\n",
    "            self.subtractSysErr = int(fields[8][2])\n",
    "\n",
    "            self.sysErrFile = fields[9][0]\n",
    "\n",
    "            chunk = fields[10][0].split()\n",
    "            self.refractiveIndex, self.partThickness = [float(n) for n in chunk]\n",
    "\n",
    "            self.zoomDesc = fields[11][0]\n",
    "\n",
    "\n",
    "            #extract intensity and phase data as numpy arrays (reshape to header parameters)\n",
    "            self.intensitymap = np.array(data[0], dtype=float).reshape(self.intensHeight, self.intensWidth)\n",
    "            self.phasemap = np.array(data[1], dtype=float).reshape(self.phaseHeight, self.phaseWidth)\n",
    "\n",
    "            #handle invalid values (given in MetroPro manual)\n",
    "            self.intensitymap[self.intensitymap >= 64512] = np.nan\n",
    "            self.phasemap[self.phasemap >= 2147483640] = np.nan\n",
    "\n",
    "            #create arrays in terms of number of waves, and height itself (in metres)\n",
    "            #by given formula\n",
    "            if self.phaseRes == 0:\n",
    "                self.R = 4096\n",
    "            elif self.phaseRes == 1:\n",
    "                self.R = 32768\n",
    "                \n",
    "            #conversion formula from MetroPro manual\n",
    "            self.waves = self.phasemap*(self.intfScaleFactor*self.obliquityFactor)/self.R\n",
    "            self.heights = self.waves*self.wavelengthIn\n",
    "             \n",
    "            \n",
    "        \n",
    "        ########################\n",
    "        ########################\n",
    "        ##pre-processing maps\n",
    "        \n",
    "        #grid points for use in some methods (?) (just using array i,j position index (can scale later))\n",
    "        self.y, self.x = np.indices(self.heights.shape)\n",
    "        \n",
    "        #apply cropping first (user-defined radius ? or default ?)\n",
    "        #self.cropped = self.crop(self.heights)\n",
    "        #orderings/logistics of this needs fixed: which array is edited? when? what effect should user cropping give?\n",
    "        #create a copy of the initial height array, this allows crop to act on those values and provide new self.heights\n",
    "        #without data loss\n",
    "        self.heights0 = self.heights.copy()\n",
    "        self.heights1 = self.interpolate_grid()\n",
    "#         self.cropped = self.heights[:]  # - slice notation actually still links the variables, need np.copy() instead\n",
    "        #store initial attributes just so they are not missing at any point\n",
    "        #they will be inaccurate initially (e.g. based on tilted map), but get updated via rotateflat()\n",
    "        self.peak, self.valley = np.nanmax(self.heights1), np.nanmin(self.heights1)\n",
    "        self.peakvalley = self.peak - self.valley\n",
    "        self.rms = np.sqrt(np.nanmean(self.heights1**2))\n",
    "        \n",
    "        #adjust to centre of valid points (centre of surface)\n",
    "        self.validrows, self.validcols = np.where(np.isfinite(self.heights1))\n",
    "        self.centre = int(np.nanmean(self.validrows)), int(np.nanmean(self.validcols))\n",
    "        self.x -= self.centre[1]\n",
    "        self.y -= self.centre[0]\n",
    "        \n",
    "                \n",
    "        #remove tilt if present\n",
    "        #note: added \"flatten\" keyword to allow user to use the map as read from file\n",
    "        #still cropped to centre the view, but without removing any tilt\n",
    "        #and also make sure to adjust valid rows & columns for this fully flattened array\n",
    "        #use a 3rd heights array - a flattened but not cropped version\n",
    "        #so will have: self.heights0 - the original data, self.heights1 - flattened version, self.heights - flattened and cropped to centre on valid area\n",
    "#         self.heights1 = self.heights0.copy()\n",
    "        if flatten:\n",
    "            self.heights1 = self.rotateflat(self.heights1)\n",
    "            self.validrows, self.validcols = np.where(np.isfinite(self.heights1))  # - update the valid points for flattened map\n",
    "            \n",
    "            \n",
    "            self.heights = self.heights1.copy()  # - keep heights1 stored; use heights as main array object for further uses\n",
    "        \n",
    "        self.crop()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    #use __str__ method to provide user summary on calling print(ZygoMap)\n",
    "    #three possible paths, depending if single file object; interface created of two maps; or simply a user-defined array\n",
    "    def __str__(self):\n",
    "        if self.filename is not None:\n",
    "            return \"ZygoMap object for file: {0}. \\nPeak-to-valley height: {1:.1f} nm \\nRMS height: {2:.1f} nm\".format(repr(self.filename), self.peakvalley*1e9, self.rms*1e9)\n",
    "        elif None not in (self.map1, self.map2, self.angle):\n",
    "            return \"ZygoMap interface object for {0} & {1} combined at angle {2:.0f} degrees. \\nPeak-to-valley height of bond: {3:.4e} m \\nRMS height of bond: {4:.4e} m\".format(repr(self.map1), repr(self.map2), self.angle, self.peakvalley, self.rms)\n",
    "        else:\n",
    "            return \"ZygoMap object for user-provided array. \\nPeak-to-valley height: {0:.4e} m \\nRMS height: {1:.4e} m\".format(self.peakvalley,self.rms)\n",
    "        \n",
    "#     @staticmethod\n",
    "    def zygoread(self, filename):\n",
    "        #works with specific ASCII format .txt files (documented in MetroPro reference guide)\n",
    "        with open(filename, \"r\") as f:\n",
    "            fstrings = f.read().split(\"\\\"\")  # - split by qoutation marks (easier to seperate string fields from data)\n",
    "\n",
    "            fields = []\n",
    "            data = []\n",
    "            section = 0\n",
    "            for elt in fstrings:\n",
    "                if \"#\" in elt:  # - use this test to show end of header section, then switch to next section\n",
    "                    section += 1\n",
    "                    pass\n",
    "\n",
    "                if section == 0:  # - processing header section\n",
    "                    #multiple fields are stored within single strings, so need to split by newline to narrow down\n",
    "                    #numbers stored within strings can be extracted afterwards\n",
    "                    #excess artifacts can be filtered out using if (True) test on elements of split string\n",
    "                    #fails on empty string, thus keeping only the relevant fields\n",
    "                    elt = elt.split(\"\\n\")\n",
    "                    values = [_ for _ in elt if _]  # - filter bad elements (e.g. \"\" which have no data and return False)\n",
    "                    #test for non-empty lists (indicates no data was found in values list)\n",
    "                    if values:\n",
    "                        fields.append(values)\n",
    "\n",
    "                elif section == 1:  # - move to data extraction for intensities and phases\n",
    "                    #the initial split left the both datasets in a single string - separate by \"#\"\n",
    "                    #split string containing a dataset then iterate through the resulting lines of 10\n",
    "                    #append all values to a 'data' array, filter as before\n",
    "                    #splitting by \"#\" will result in 2 lists stored in the overall 'data' list\n",
    "                    #i.e. can extract: intensities = data[0], phases = data[1]\n",
    "                    for line in elt.split(\"#\"):\n",
    "                        values = [_ for _ in line.split() if _]\n",
    "                        if values:\n",
    "                            data.append(values)\n",
    "                        \n",
    "        return fields, data\n",
    "    \n",
    "    def interpolate_grid(self, array=None, x_step=1, y_step=1):\n",
    "        #initial interpolation stage to cover any missing values\n",
    "        #using scipy's griddata\n",
    "        #the valid values are passed in, along with the new grid to fit to\n",
    "        #this can be the exact same grid, or an up/down-scaled version using grid_step argument\n",
    "        if array is None:\n",
    "            array = self.heights0\n",
    "\n",
    "        dims = array.shape\n",
    "        x,y = np.indices(dims)\n",
    "        vectarray = np.dstack([x,y,array])\n",
    "        vectarray = vectarray.reshape(vectarray.size//3, 3)\n",
    "\n",
    "        sample_xaxis = np.arange(0, dims[0], x_step)\n",
    "        sample_yaxis = np.arange(0, dims[1], y_step)\n",
    "\n",
    "        ax_dims = sample_xaxis.shape[0], sample_yaxis.shape[0]\n",
    "\n",
    "        X = np.vstack(np.tile(sample_xaxis, ax_dims[1]).reshape(ax_dims[1], ax_dims[0])).T\n",
    "        Y = np.vstack(np.tile(sample_yaxis, ax_dims[0]).reshape(ax_dims[0], ax_dims[1]))\n",
    "\n",
    "        va = vectarray[np.isfinite(vectarray[:,2])]\n",
    "        interped = scipy.interpolate.griddata((va[:,0], va[:,1]), va[:,2], (X,Y), method=\"cubic\")\n",
    "\n",
    "        return interped\n",
    "    \n",
    "    def crop(self, radius=0, reflatten=True):\n",
    "        #allow user to crop to extract only data within some radius\n",
    "        #most needed to avoid large edge effects (discontinuities)\n",
    "        #use the (stored) centred x and y positions to check against radius\n",
    "        #make a new cropped array where points outwith radius are set to nan\n",
    "        #and \"zoom in\" to store only the array rows & columns within the valid range\n",
    "        #will run during __init__(), with default radius = 0, so can avoid editing if radius is default\n",
    "        #and only do if user chose a (non-zero) radius\n",
    "        #thus only the centring of view by array slicing is performed (no need for separate functions)\n",
    "        \n",
    "        #set cropped array based on original state of heights (so not cropping multiple times and losing data)\n",
    "#         cropped = self.heights0.copy()\n",
    "        cropped = self.heights1.copy()\n",
    "        \n",
    "        if radius != 0:\n",
    "            #if radius non-zero, we will be setting valid points to invalid (nan)\n",
    "            #use centred x,y grid points for full data array to make a mask for points outside radius\n",
    "            #then just change these points to nan (thus matching the pre-existing background)\n",
    "            outsideR = self.x**2 + self.y**2 > radius**2\n",
    "            cropped[outsideR] = np.nan\n",
    "            \n",
    "            #could add a flag/callback here to automatically re-apply rotations after crops (otherwise advise user to do it)\n",
    "            #e.g. if callback = True -> rotateflat()\n",
    "        \n",
    "        #now find the extreme bounds of valid points and slice the array to show only the data within\n",
    "        validrows, validcols = np.where(np.isfinite(cropped))\n",
    "        lft, rgt, upp, low = np.nanmin(validcols), np.nanmax(validcols), np.nanmin(validrows), np.nanmax(validrows)\n",
    "        \n",
    "        \n",
    "        cropped = cropped[upp:low+1, lft:rgt+1]\n",
    "        self.heights = cropped.copy()\n",
    "        \n",
    "        if reflatten:\n",
    "            self.heights = self.rotateflat(self.heights)\n",
    "        \n",
    "        #update valid positions, after rows/columns removed\n",
    "        self.validrows, self.validcols = np.where(np.isfinite(self.heights))\n",
    "        self.centre = int(np.nanmean(self.validcols)),int(np.nanmean(self.validrows))\n",
    "        \n",
    "        \n",
    "        return cropped\n",
    "    \n",
    "    def rotateflat(self, array=None):\n",
    "        #\"array\" argument left so normal or cropped maps can be used (i.e. self.heights vs self.cropped)\n",
    "        #detect array=None to mean default self.heights\n",
    "        if array is None:\n",
    "            array = self.heights\n",
    "        \n",
    "        #fit plane to data with linear least squares\n",
    "        dims = array.shape\n",
    "        x,y = np.indices(dims)\n",
    "\n",
    "        #reduce points to exclude nan's - scipy's lstsq can't handle them\n",
    "        valid_mask = np.isfinite(array)\n",
    "\n",
    "        #create a stack of [x,y,height] position vectors for the valid grid points\n",
    "        vectarray = np.dstack([x[valid_mask], y[valid_mask], array[valid_mask]])\n",
    "        vectarray = vectarray.reshape(vectarray.size//3, 3)\n",
    "\n",
    "        #construct data to model with additional constant (1) for the regression line\n",
    "        #will solve for x coefficients in matrix equation Ax = Z\n",
    "        A = np.c_[vectarray[:,0], vectarray[:,1], np.ones(vectarray.shape[0])]\n",
    "\n",
    "        #solve for coefficients of least squares minimised plane\n",
    "        #i.e. there are three coefficients for \n",
    "        C, *_, = scipy.linalg.lstsq(A, vectarray[:,2])\n",
    "\n",
    "        #recreate the fitted plane values\n",
    "        Z = C[0] * x[valid_mask] + C[1] * y[valid_mask] + C[2]\n",
    "\n",
    "\n",
    "        #return the array with the planar tilt heights taken away\n",
    "        new_array = array.copy()\n",
    "        new_array[valid_mask] = array[valid_mask] - Z\n",
    "        \n",
    "        #update parameters for flattened heights\n",
    "        self.peak, self.valley = np.nanmax(new_array), np.nanmin(new_array) # - need to consider all rotated values, even if they are not going to be stored (outwith bounds)\n",
    "        self.peakvalley = self.peak - self.valley\n",
    "        self.rms = np.sqrt(np.nanmean(new_array**2))\n",
    "        \n",
    "        #update the stored heights array\n",
    "        self.heights = new_array.copy()\n",
    "        \n",
    "        return new_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5291970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ztestf(*args):  # - optimisation of rotation around z-axis of upper map w.r.t lower map\n",
    "    angz = args[0][0]  # - optimize.minimize gives angz as [0.] (why?) so needs extracted from list as well as args tuple\n",
    "    lowermap, uppermap = args[1],args[2]\n",
    "\n",
    "    dims = uppermap.shape\n",
    "    \n",
    "    #now get new rotated array (rotating around z/in x-y plane)\n",
    "    #using scipy.ndimage.rotate()\n",
    "    #order=0 means no additional interpolation of values when rotating\n",
    "    #reshape=False maintains original dimensions (used in case of rotating outside of original shape - not applicable here)\n",
    "    #use mode=\"constant\" and cval=np.nan to fill out all (and perhaps new) invalid points with nan\n",
    "    newheights = scipy.ndimage.rotate(uppermap, angz, order=0, reshape=False, mode=\"constant\", cval=np.nan)\n",
    "    \n",
    "    #simulate the surface contact, using simple 1 point of contact\n",
    "    #one map flipped horizontally and negated, their addition describes the interface heights\n",
    "    interface = -newheights[::-1] + lowermap\n",
    "    interface += abs(np.nanmin(interface))  # - set contact point to be zero height (negative values are non-physical intersection of surfaces)\n",
    "    interface -= np.nanmean(interface)\n",
    "    \n",
    "    #again minimising peak-to-valley height, though a sum of squares approach could be used\n",
    "    peakvalley = np.nanmax(interface) - np.nanmin(interface)\n",
    "    \n",
    "    return peakvalley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76637cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchdims(map1,map2):\n",
    "    #given two arrays (not map objects), truncate them to their lowest shared dimensions to be able to sum them\n",
    "    #note: should probably choose to add rows/columns rather than remove data\n",
    "    m1,m2 = map1.copy(),map2.copy()\n",
    "    \n",
    "    m1dims, m2dims = m1.shape, m2.shape\n",
    "    diffs = [(m1dims[0] - m2dims[0]), (m1dims[1] - m2dims[1])]  # - find difference in number of rows & columns between arrays\n",
    "    \n",
    "    #two types of slices for which dimension is the largest between the two maps\n",
    "    #use modulo % to check divisibility, // to do whole number division\n",
    "    #then slice from each end of array (avoid bias/truncating on one side)\n",
    "    #take the divisor result from both sides, then take the remainder from end of array\n",
    "    #balances as much as possible, but odd-numbered differences will be asymmetric (just take remaining 1 from end of array)\n",
    "    #use (len(array) - number) to do backwards slice - needed for minus zero slice which is treated as zero\n",
    "    #using len() gives an absolute index rather than relative\n",
    "    #addition of abs() makes things easier\n",
    "    \n",
    "    #for rows\n",
    "    rem,div = (diffs[0] % 2), (diffs[0]//2)\n",
    "    if m1dims[0] > m2dims[0]:\n",
    "        m1 = m1[abs(div):m1.shape[0]-abs(div+rem),:]\n",
    "    elif m1dims[0] < m2dims[0]:\n",
    "        m2 = m2[abs(div):m2.shape[0]-abs(div+rem),:]\n",
    "        \n",
    "    #for columns\n",
    "    rem,div = (diffs[1] % 2), (diffs[1]//2)\n",
    "    if m1dims[1] > m2dims[1]:\n",
    "        m1 = m1[:, abs(div):m1.shape[1]-abs(div+rem)]\n",
    "    elif m1dims[1] < m2dims[1]:\n",
    "        m2 = m2[:, abs(div):m2.shape[1]-abs(div+rem)]\n",
    "    \n",
    "    return m1,m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "246bf653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinemaps(lowermap, uppermap, optimised=True, output=True):\n",
    "    m1,m2 = lowermap.heights, uppermap.heights\n",
    "    #function to combine ZygoMap objects\n",
    "    #flips and negates values of the 2nd map \"uppermap\"\n",
    "    #emulating the surface placed faced down on the other\n",
    "    #returns ZygoMap object from the combination of the lower map and the transformed uppermap\n",
    "    #where the magnitude of largest negative has been added back as an offset to prevent non-physical overlap of surfaces\n",
    "    \n",
    "    #check for equal shapes (changed to automatically crop to smallest shared values)\n",
    "    #use matchdims() function, will return arrays with equal rows,columns for direct addition of arrays\n",
    "    if m1.shape != m2.shape:\n",
    "        m1,m2 = matchdims(m1,m2)\n",
    "    \n",
    "    #find optimised angle of rotation (of uppermap with respect to lowermap)\n",
    "    #minimise the peakvalley height with rotation angle around z-axis\n",
    "    #NOTE: previous rotation method not working the same for z rotations\n",
    "    #using scipy.ndimage.rotate (with order=0 to maintain array values (no spline interpolation))\n",
    "    #large angular range needed -> need brute() function to get the accurate value\n",
    "    #define angular range by ranges=(slice(0,360),) (the slice object is preferred by brute function definition)\n",
    "    optimalangle = 0\n",
    "    if optimised == True:\n",
    "        optimalangle = scipy.optimize.brute(ztestf, ranges=((slice(0,360),)), args=(m1,m2))[0]\n",
    "    \n",
    "        #apply this angle with scipy.ndimage.rotate() to get new array of the rotated uppermap\n",
    "        #use this array directly for the interface (in place of uppermap.heights), and leave each individual map untouched\n",
    "        #should store some indicator for user of the optimal angle used (property of interfacemap ?)\n",
    "        newheights = scipy.ndimage.rotate(m2, optimalangle, order=0, reshape=False, mode=\"constant\", cval=np.nan)\n",
    "    else:\n",
    "        newheights = m2.copy()\n",
    "\n",
    "    #flip and negate uppermap, then add to lower map for interface\n",
    "    #note: using only simple one-point contact\n",
    "    #for more realistic simulation, want to find 3 points or simulate how the upper surface would \"settle\" onto lower\n",
    "    #experimented (manually simulating 2 rotations based on position of point around centre)\n",
    "    #but not a clear successful method, would leave as future work\n",
    "    interface = -newheights[::-1] + m1\n",
    "    interface += abs(np.nanmin(interface))  # - add back largest overlap, to leave maps just touching\n",
    "    interface -= np.nanmean(interface)  # - centre in z-axis around mean\n",
    "        \n",
    "    #construct as ZygoMap object\n",
    "    #providing basic details about its construction (the combination of which maps at what angle)\n",
    "    if hasattr(lowermap, \"filename\") and hasattr(uppermap, \"filename\"):\n",
    "        interfacemap = ZygoMap(array=interface, map1=lowermap.filename, map2=uppermap.filename, angle=optimalangle)\n",
    "    else:\n",
    "        interfacemap = ZygoMap(array=interface)\n",
    "    \n",
    "    #give user some knowledge on the optimised set-up\n",
    "    #this could be moved elsewhere possibly for better access ->  added __str__() method to allow user to print() attributes\n",
    "    #added flags for optimisation and output\n",
    "    #set output to false for auto-comparison, so can display at end in a sorted order\n",
    "    if optimised and output:\n",
    "        if hasattr(lowermap, \"filename\") and hasattr(uppermap, \"filename\"):  # - if each defined from files, can use their filenames as references\n",
    "            print(\"Maps combined for optimal angle of {0:.2f} degrees\\n\\\n",
    "            {1} clockwise w.r.t {2}\".format(optimalangle,uppermap.filename,lowermap.filename))\n",
    "        else:\n",
    "            print(\"Maps combined for optimal angle of {0:.2f} degrees\\n\\\n",
    "            (map2 clockwise w.r.t map1)\".format(optimalangle))\n",
    "        print(\"Optimised peak-to-valley height: {0} m\".format(interfacemap.peakvalley))\n",
    "        print(\"Optimised RMS height: {0} m\".format(interfacemap.rms))\n",
    "        \n",
    "    \n",
    "    return interfacemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d61d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparebonds(zmaps, sort=\"both\", plot=False):\n",
    "    #NOTE: using itertools.combinations module\n",
    "    #for a list (or maybe dict as well ?) of map objects, iterate through every pair combination\n",
    "    #comparing bonds by peak-to-valley height & RMS height\n",
    "    #additionally, can print information about optimal angle (around z-axis) to combine each pair\n",
    "    \n",
    "    #attain array from generator object returned by combinations (using n=2 items per combo)\n",
    "    mpairs = np.array(list(combinations(zmaps, 2)))\n",
    "    \n",
    "    #combine maps, creating interface object for each pair (of ZygoMap class, defined with array rather than filename)\n",
    "    #will store the PV & RMS values for each in numpy arrays, to then be sorted best to worst\n",
    "    #choice to store the interfaces ? - for low number of arrays this should be ok\n",
    "    \n",
    "    #initialise empty arrays which will store the PV/RMS as calculated (necessary if not storing each interface)\n",
    "    pvValues = np.zeros(len(mpairs))\n",
    "    rmsValues = np.zeros(len(mpairs))\n",
    "    \n",
    "    interfacemaps = np.zeros(len(mpairs), dtype=object)  # - to store each combo pair's interfacemap (ZygoMap object)\n",
    "    #note: may not be so simple - only local to function, may need to either return interfacemaps or create as global variable\n",
    "    for i in range(len(mpairs)):\n",
    "        combo = mpairs[i]\n",
    "        interfacemap = combinemaps(*combo, output=False)\n",
    "        pvValues[i] = interfacemap.peakvalley\n",
    "        rmsValues[i] = interfacemap.rms\n",
    "        \n",
    "        interfacemaps[i] = interfacemap\n",
    "        \n",
    "    #now, sort for display\n",
    "    #sort the mpairs list differently for either pv or rms, storing each separately\n",
    "    #allow \"sort\" keyword to limit comparison to only pv or only rms (defaults to \"both\")\n",
    "    \n",
    "    #sort combos by lowest peak-valley height\n",
    "    if sort in (\"both\",\"pv\"):\n",
    "        lowestpv = mpairs[pvValues.argsort()]\n",
    "        print(\"Sample Bonds sorted by lowest peak-to-valley height:\\n\")\n",
    "        for i in range(len(lowestpv)):\n",
    "            combo = lowestpv[i]\n",
    "            print(\"{} - \".format(i+1),*[m.filename for m in combo])\n",
    "            print(\"Peak-to-valley Height: {0:.1f} nm\".format(pvValues[pvValues.argsort()][i] * 1e9))  # - convert to nanometres\n",
    "            print(\"RMS Height: {0:.1f} nm\".format(rmsValues[pvValues.argsort()][i] * 1e9))\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    #sort combos by lowest rms height\n",
    "    if sort in (\"both\",\"rms\"):\n",
    "        lowestrms = mpairs[rmsValues.argsort()]\n",
    "        print(\"Sample Bonds sorted by lowest RMS height:\\n\")\n",
    "        for i in range(len(lowestrms)):\n",
    "            combo = lowestrms[i]\n",
    "            print(\"{} - \".format(i+1),*[m.filename for m in combo])\n",
    "            print(\"RMS Height: {0:.1f} nm\".format(rmsValues[rmsValues.argsort()][i] * 1e9))\n",
    "            print(\"Peak-to-valley Height: {0:.1f} nm\".format(pvValues[rmsValues.argsort()][i] *1e9))\n",
    "            print(\"\\n\")\n",
    "            \n",
    "    if plot is True:\n",
    "        if sort in (\"both\",\"pv\"):\n",
    "            #sort the found pv & rms heights, ordering by the lowest pv in both cases (keep both values aligned per combo)\n",
    "            plt.figure(figsize=(10,6))\n",
    "            plt.plot(pvValues[pvValues.argsort()], \"o\", label=\"Peak-Valley\")\n",
    "            plt.plot(rmsValues[pvValues.argsort()], \"o\", label=\"RMS\")\n",
    "            plt.title(\"Bond height values comparison (sorted by lowest peak-valley value)\\n\")\n",
    "            \n",
    "            plt.xlabel(\"Maps used in simulated bond\")\n",
    "            plt.ylabel(\"Height of bond interface (nm)\")\n",
    "            plt.xticks(range(len(mpairs)), np.array([m.map1.split(\".\")[0]+\"\\n\"+m.map2.split(\".\")[0] for m in interfacemaps])[pvValues.argsort()], rotation=0)\n",
    "            plt.yticks(np.arange(0, max(pvValues) + 10e-9, 10e-9))\n",
    "            plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(-9,-9), useMathText=True)\n",
    "            plt.axhline(60e-9, linestyle=\"solid\", linewidth=3, color=\"r\")\n",
    "            plt.legend(loc=\"upper left\", fontsize=14)\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            \n",
    "        if sort in (\"both\",\"rms\"):\n",
    "            #sort the found pv & rms heights, ordering by the lowest rms in both cases (keep both values aligned per combo)\n",
    "            plt.figure(figsize=(10,6))\n",
    "            plt.plot(pvValues[rmsValues.argsort()], \"o\", label=\"Peak-Valley\")\n",
    "            plt.plot(rmsValues[rmsValues.argsort()], \"o\", label=\"RMS\")\n",
    "            plt.title(\"Bond height values comparison (sorted by lowest RMS value)\\n\")\n",
    "            \n",
    "            plt.xlabel(\"Maps used in simulated bond\")\n",
    "            plt.ylabel(\"Height of bond interface (nm)\")\n",
    "            plt.xticks(range(len(mpairs)), np.array([m.map1.split(\".\")[0]+\"\\n\"+m.map2.split(\".\")[0] for m in interfacemaps])[rmsValues.argsort()], rotation=0)\n",
    "            plt.yticks(np.arange(0, max(pvValues) + 10e-9, 10e-9))\n",
    "            plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(-9,-9), useMathText=True)\n",
    "            plt.axhline(60e-9, linestyle=\"solid\", linewidth=3, color=\"r\")\n",
    "            plt.legend(loc=\"upper left\", fontsize=14)\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            \n",
    "    return  # - nothing right now (simplest for usability) but could offer the sorted arrays and all interfacemaps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
